FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=15 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.82409167552317583727e+01) (1, 2.75818323213650018477e-01) (2, 3.51319321859670907759e-01) (3, 3.58341032136274606490e-01) (4, 2.46293575931383346145e-01) (5, -1.31168574463244480555e+00) (6, -1.10222648714144400017e+00) (7, -6.85827378096601947277e+00) (8, -7.42733470657061189968e-01) (9, -1.60162737018936796041e+00) (10, -1.27630682455185895385e+00) (11, -5.23207556742569579455e+00) (12, -1.72098388851679184874e+00) (13, -2.38304202051830049669e+00) (14, 4.92559219990053787086e+00) (0, 7.32020121412875479638e-03) (1, -5.96329446311494107413e-02) (2, 1.35473955993155401739e-02) (3, -2.53497462149163271805e-02) (4, -1.12655217515995192956e-01) (5, 4.15420914887208281296e-01) (6, 1.71507761342162412532e+00) (7, -7.20636944642393667548e-02) (8, 1.20970390519936721319e+00) (9, 1.07271769647396042480e+00) (10, 6.64300059391391584107e-01) (11, 4.19790773146005768979e-01) (12, 6.85125824300928165655e-01) (13, 7.48842023582157567674e-01) (14, -8.90798143572514716793e-02) (0, -2.71208452393384320811e-02) (1, -1.29190494479345857615e-01) (2, -1.64342952133822023386e-01) (3, -4.51904509083505614986e-02) (4, -1.89198878766703187937e-01) (5, -1.29610446669801615549e+00) (6, -2.87771066858927893062e-01) (7, -4.58960848833576268158e-02) (8, -3.45338877509888142470e+00) (9, -6.89882793774961422528e-01) (10, -4.36433488703472982628e-01) (11, -8.62969963194422928776e-02) (12, -6.63227073630934693682e-01) (13, -1.65752677357637670519e-02) (14, 1.07185671704638774138e-01) (0, -1.01676302363248212413e-02) (1, -1.76081408919500859156e-01) (2, -1.43686318011688740626e-01) (3, -3.64628793406123873772e-04) (4, -5.41360203043695295544e-02) (5, -1.35340420348055112676e+00) (6, -2.08560250750578907164e-01) (7, 4.39851292886128258930e-02) (8, -3.94103128438318695004e+00) (9, -5.28206629238006541982e-01) (10, -3.60973679382648016123e-01) (11, -3.43725888372950899585e-02) (12, -9.42324096996094762169e-01) (13, 1.46862642642215573963e-01) (14, 8.28253874953873425735e-02) (0, 2.23040521376896755390e-01) (1, 8.93197881550154143548e-02) (2, -9.83630937963166224192e-02) (3, -7.43451861172356592844e-02) (4, 3.95328628391585154556e-02) (5, -8.31032181859139851277e-01) (6, -9.22206220743080118396e-01) (7, 6.99022870039901211836e-02) (8, -8.68939874348464869058e-01) (9, -7.19872392191841403708e-01) (10, -1.03221667597162514163e+00) (11, -1.51297761345058040527e-01) (12, -6.11944589780465286744e-01) (13, -2.80236614419352492167e-01) (14, 4.19056038581540168941e-01) (0, 5.91495068723197459093e-01) (1, -7.10817159852764196559e-02) (2, -1.16001846036693744002e-02) (3, -7.45343224844715185329e-02) (4, -7.60428229114791937038e-02) (5, 1.90254847139423810543e-01) (6, 1.75938055202550167055e-02) (7, -7.93347611637595512279e-02) (8, 9.72967435993731255550e-01) (9, -3.77465132687816617985e-01) (10, -1.20924143829645980297e+00) (11, -1.35085061877708478839e+00) (12, 9.91500486852772977553e-02) (13, -1.88914903514504195492e+00) (14, 3.08663490283290542493e-01) (0, -1.79960446764798505381e-02) (1, -7.16520471147193277472e-02) (2, 8.01666641959057207911e-02) (3, -7.70836582056178137856e-02) (4, -4.17263542882098381614e-02) (5, -1.06964574774665899248e+00) (6, -9.95339943467620891226e-01) (7, 1.17662050900455394942e-01) (8, -3.51271324218033154096e+00) (9, -6.10473666051182695114e-01) (10, -1.51012967373073347943e+00) (11, -1.10878671092903169360e-01) (12, -6.21773343549863022339e-01) (13, 1.08080067419559222586e-02) (14, 7.77219236997444690163e-02) (0, 1.64997348250507798184e+01) (1, 3.40900685940026926257e-01) (2, 4.24847986850976633288e-01) (3, 2.90071104023694681384e-01) (4, 3.86724587831735300281e-01) (5, -8.32077966910343691520e-02) (6, -3.88732701707929007018e-01) (7, -6.97075942395442371691e+00) (8, -6.88906854105918453612e-01) (9, -1.69852717856622748016e+00) (10, 5.89984884512644164323e-02) (11, 5.54787234103968351917e-01) (12, 1.00474341444928128020e+00) (13, 3.89768456978269395297e-01) (14, 2.10183732913430088018e+00) (0, 1.93479740051531834411e+01) (1, 3.69663864382508866591e-01) (2, 4.04581543066505067152e-01) (3, 4.94417246439460389418e-01) (4, 4.01939604439738862318e-01) (5, 7.41449947783659357725e-01) (6, -9.47601348484833239105e-01) (7, -8.08630673336315553001e+00) (8, -1.42527634683579385033e+00) (9, -1.88875692145560658552e+00) (10, -2.06926410216627720828e-01) (11, -1.49788780648462099832e-01) (12, 3.54969810906198557365e-01) (13, 4.66003689920194252849e-01) (14, 2.09085395971336662768e+00) (0, 2.04038218489314715498e+01) (1, 2.60738353527270649845e-01) (2, 3.59084564543448780949e-01) (3, 3.56660823620044087345e-01) (4, 2.79155227637969349797e-01) (5, -1.16376377162710009650e+00) (6, -6.99622108176411572344e-01) (7, -6.12774147782921030370e+00) (8, -2.43845780623982100188e-01) (9, -4.80292857245113669062e-01) (10, -1.04426637623520512932e+00) (11, -2.97305458057730387367e+00) (12, -1.62696138003029222574e+00) (13, -3.72931868803261856726e+00) (14, 2.99942883406708205030e+00) (15, -1.46935752294595128875e-01) (16, 4.14290568304235995445e-01) (17, -3.13544517189644489363e-01) (18, -3.52562075287483844832e-01) (19, -8.25497850751378936529e-01) (20, 2.70430740094177307631e-02) (21, -3.54022226095121572698e-01) (22, -1.03591653753564619245e-01) (23, -1.37312266279504574529e-01) (24, -1.89810356758172454894e-01) (25, 5.82942036036282362765e-01) 
